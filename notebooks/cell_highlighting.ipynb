{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src import T5ModelForTableCellHighlighting\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from utils import process_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/cell_highlighting/t5.json\", \"rb\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ModelForTableCellHighlighting(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_cell_highlighting_flan_t5_xl_pretrain/checkpoints/epoch=2.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/test_wiki_tq_reason_without_answer.pkl\", \"rb\") as f:\n",
    "    reasons_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer.tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reasons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(idx):\n",
    "\n",
    "    reason = reasons_list[idx]\n",
    "\n",
    "    table = dataset[\"test\"][idx][\"table\"]\n",
    "    table_column_names = table[\"header\"]\n",
    "    table_content_values = table[\"rows\"]\n",
    "\n",
    "    table_column_names = [x.lower() for x in table_column_names]\n",
    "\n",
    "    table = \"[HEADER] \" + \" | \".join(table_column_names)\n",
    "    for row_id, row in enumerate(table_content_values):\n",
    "        row = [x.lower() for x in row]\n",
    "        table += f\" [ROW] {row_id}: \" + \" | \".join(row) \n",
    "\n",
    "    tokenized_input = tokenizer(reason, table, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = config.tokenizer.input_max_length, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "\n",
    "\n",
    "    output_ids = model.model.generate(input_ids = tokenized_input[\"input_ids\"].to(\"cuda:0\"), attention_mask = tokenized_input[\"attention_mask\"].to(\"cuda:0\"),\n",
    "                                      max_new_tokens = config.tokenizer.output_max_length, num_beams = 3, early_stopping = True).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_cells = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "    return predicted_cells\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighted_cells_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(reasons_list)), position=0, leave = True, total = len(reasons_list)):\n",
    "    x = predict(i).split(\", \")\n",
    "    x = [a.strip() for a in x]\n",
    "\n",
    "    highlighted_cells_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(highlighted_cells_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighted_cells_list[2059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/wiki_tq_test_highlighted_cell_flant_t5_reasons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(highlighted_cells_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the character index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pickle\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"wikitablequestions\")[\"test\"]\n",
    "\n",
    "with open(\"datasets/wiki_tq_test_highlighted_cell_flant_t5_reasons.pkl\", \"rb\") as f:\n",
    "    train_highlighted_cells = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_highlighted_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_relevance_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "\n",
    "    question = train_dataset[i][\"question\"]\n",
    "    highlighted_cells = train_highlighted_cells[i]\n",
    "\n",
    "    table = train_dataset[i][\"table\"]\n",
    "    table_column_names = table[\"header\"]    \n",
    "    table_content_values = table[\"rows\"]\n",
    "\n",
    "    table_df = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "    \n",
    "    tokenized_input = tokenizer(table_df, question, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = 960, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "    \n",
    "    tokenized_highlighted_cells = []\n",
    "    hard_relevance_label = torch.zeros((tokenized_input[\"input_ids\"].shape[1]))\n",
    "    for h_cell in highlighted_cells:\n",
    "        x = tokenizer(answer = h_cell, add_special_tokens = False,\n",
    "                            return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)[\"input_ids\"].tolist()\n",
    "        for ele in x[0]:\n",
    "            hard_relevance_label[tokenized_input[\"input_ids\"].squeeze() == ele] = 1\n",
    "        \n",
    "    hard_relevance_labels.append(hard_relevance_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hard_relevance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_relevance_labels[2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/wiki_tq_test_highlighted_cell.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_relevance_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "start = 0\n",
    "while start < len(s1):\n",
    "    index = s1.find(s2, start)\n",
    "    if index != -1:\n",
    "        indices.append(index)\n",
    "        start = index + 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell highlighting on Sequential QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src import T5ModelForTableCellHighlighting\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from utils import process_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"msr_sqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/cell_highlighting/t5.json\", \"rb\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ModelForTableCellHighlighting(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_cell_highlighting_flan_t5_xl_pretrain/checkpoints/epoch=2.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/test_seq_qa_reason_without_answer_flant5.pkl\", \"rb\") as f:\n",
    "    reasons_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer.tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reasons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(idx):\n",
    "\n",
    "    reason = reasons_list[idx]\n",
    "\n",
    "    table_column_names = dataset[\"test\"][idx][\"table_header\"]\n",
    "    table_content_values = dataset[\"test\"][idx][\"table_data\"]\n",
    "\n",
    "    table_column_names = [x.lower() for x in table_column_names]\n",
    "\n",
    "    table = \"[HEADER] \" + \" | \".join(table_column_names)\n",
    "    for row_id, row in enumerate(table_content_values):\n",
    "        row = [x.lower() for x in row]\n",
    "        table += f\" [ROW] {row_id}: \" + \" | \".join(row) \n",
    "\n",
    "    tokenized_input = tokenizer(reason, table, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = config.tokenizer.input_max_length, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "\n",
    "\n",
    "    output_ids = model.model.generate(input_ids = tokenized_input[\"input_ids\"].to(\"cuda:0\"), attention_mask = tokenized_input[\"attention_mask\"].to(\"cuda:0\"),\n",
    "                                      max_new_tokens = config.tokenizer.output_max_length, num_beams = 3, early_stopping = True).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_cells = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "    return predicted_cells\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "highlighted_cells_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(reasons_list)), position=0, leave = True, total = len(reasons_list)):\n",
    "    x = predict(i).split(\", \")\n",
    "    x = [a.strip() for a in x]\n",
    "\n",
    "    highlighted_cells_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/seq_qa_test_highlighted_cell_flant_t5_reasons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(highlighted_cells_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/seq_qa_test_highlighted_cell_flant_t5_reasons.pkl\", \"rb\") as f:\n",
    "    highlighted_cells_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(highlighted_cells_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_relevance_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neulab/omnitab-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "\n",
    "    question = \" \".join(train_dataset[i][\"question_and_history\"])\n",
    "    table_column_names = train_dataset[i][\"table_header\"]\n",
    "    table_content_values = train_dataset[i][\"table_data\"]\n",
    "    # question = train_dataset[i][\"question\"]\n",
    "    highlighted_cells = highlighted_cells_list[i]\n",
    "\n",
    "    # table = train_dataset[i][\"table\"]\n",
    "    # table_column_names = table[\"header\"]    \n",
    "    # table_content_values = table[\"rows\"]\n",
    "\n",
    "    table_df = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "    \n",
    "    tokenized_input = tokenizer(table_df, question, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = 896, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "    \n",
    "    tokenized_highlighted_cells = []\n",
    "    hard_relevance_label = torch.zeros((tokenized_input[\"input_ids\"].shape[1]))\n",
    "    for h_cell in highlighted_cells:\n",
    "        x = tokenizer(answer = h_cell, add_special_tokens = False,\n",
    "                            return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)[\"input_ids\"].tolist()\n",
    "        for ele in x[0]:\n",
    "            hard_relevance_label[tokenized_input[\"input_ids\"].squeeze() == ele] = 1\n",
    "        \n",
    "    hard_relevance_labels.append(hard_relevance_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hard_relevance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_relevance_labels[100].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/seq_qa_test_highlighted_cell.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_relevance_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq QA Reason and Cell Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"msr_sqa\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/seq_qa_reason_without_answer_flant5.pkl\", \"rb\") as f:\n",
    "    train_reasons = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/seq_qa_train_highlighted_cell_flant_t5_reasons.pkl\", \"rb\") as f:\n",
    "    train_highlighted_cells = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" \".join(train_dataset[idx][\"question_and_history\"])\n",
    "table_column_names = train_dataset[idx][\"table_header\"]\n",
    "table_content_values = train_dataset[idx][\"table_data\"]\n",
    "answer_text = \", \".join(train_dataset[idx][\"answer_text\"])\n",
    "\n",
    "table = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "reason = train_reasons[idx]\n",
    "highlighted_cells = train_highlighted_cells[idx]\n",
    "\n",
    "print(\"Question: \", question, end = \"\\n\\n\")\n",
    "print(\"Answer: \", answer_text, end = \"\\n\\n\")\n",
    "print(\"Reason: \", reason, end = \"\\n\\n\")\n",
    "print(\"Highlight: \", highlighted_cells, end = \"\\n\\n\")\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell highlighting on FetaQA using flant5-xl reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src import T5ModelForTableCellHighlighting\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from utils import process_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"DongfuTingle/FeTaQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/cell_highlighting/t5.json\", \"rb\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ModelForTableCellHighlighting(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"logs/table_cell_highlighting_flan_t5_xl_pretrain/checkpoints/epoch=2.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/test_feta_qa_reason_without_answer_flant5.pkl\", \"rb\") as f:\n",
    "    reasons_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer.tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(idx):\n",
    "\n",
    "    reason = reasons_list[idx]\n",
    "\n",
    "    table_column_names = dataset[\"test\"][idx][\"table_array\"][0]\n",
    "    table_content_values = dataset[\"test\"][idx][\"table_array\"][1:]\n",
    "\n",
    "    table_column_names = [x.lower() for x in table_column_names]\n",
    "\n",
    "    table = \"[HEADER] \" + \" | \".join(table_column_names)\n",
    "    for row_id, row in enumerate(table_content_values):\n",
    "        row = [x.lower() for x in row]\n",
    "        table += f\" [ROW] {row_id}: \" + \" | \".join(row) \n",
    "\n",
    "    tokenized_input = tokenizer(reason, table, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = config.tokenizer.input_max_length, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "\n",
    "\n",
    "    output_ids = model.model.generate(input_ids = tokenized_input[\"input_ids\"].to(\"cuda:0\"), attention_mask = tokenized_input[\"attention_mask\"].to(\"cuda:0\"),\n",
    "                                      max_new_tokens = config.tokenizer.output_max_length, num_beams = 3, early_stopping = True).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_cells = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "    return predicted_cells\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighted_cells_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(reasons_list)), position=0, leave = True, total = len(reasons_list)):\n",
    "    x = predict(i).split(\", \")\n",
    "    x = [a.strip() for a in x]\n",
    "\n",
    "    highlighted_cells_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/feta_qa_test_highlighted_cell_flant_t5_reasons.pkl\", \"wb\") as f:\n",
    "    pickle.dump(highlighted_cells_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_relevance_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "\n",
    "    question = \" \".join(train_dataset[i][\"question\"])\n",
    "    table_column_names = train_dataset[i][\"table_array\"][0]\n",
    "    table_content_values = train_dataset[i][\"table_array\"][1:]\n",
    "    # question = train_dataset[i][\"question\"]\n",
    "    highlighted_cells = highlighted_cells_list[i]\n",
    "\n",
    "    # table = train_dataset[i][\"table\"]\n",
    "    # table_column_names = table[\"header\"]    \n",
    "    # table_content_values = table[\"rows\"]\n",
    "\n",
    "    table_df = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "    \n",
    "    tokenized_input = tokenizer(table_df, question, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = 896, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)\n",
    "    \n",
    "    tokenized_highlighted_cells = []\n",
    "    hard_relevance_label = torch.zeros((tokenized_input[\"input_ids\"].shape[1]))\n",
    "    for h_cell in highlighted_cells:\n",
    "        x = tokenizer(answer = h_cell, add_special_tokens = False,\n",
    "                            return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)[\"input_ids\"].tolist()\n",
    "        for ele in x[0]:\n",
    "            hard_relevance_label[tokenized_input[\"input_ids\"].squeeze() == ele] = 1\n",
    "    \n",
    "    hard_relevance_labels.append(hard_relevance_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/feta_qa_test_highlighted_cell.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_relevance_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

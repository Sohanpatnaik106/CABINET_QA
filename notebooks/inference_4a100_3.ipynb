{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Generation using Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed, create_synthetic_column\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from src import TapexModelForConditionalGeneration, TapexModelForMaskedLanguageModelling, TapexModelForSequenceClassification\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from data import SciGenDataset\n",
    "\n",
    "from utils import prepare_dataloaders, prepare_models\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import Trainer, Logger, LightningTrainer\n",
    "\n",
    "\n",
    "from src import BartModelForMaskedLM, BartModelForConditionalGeneration, BartModelForSequenceClassification\n",
    "\n",
    "\n",
    "from src import compute_metrics\n",
    "\n",
    "import wandb\n",
    "\n",
    "from src import GPT2ModelForConditionalGeneration, T5ModelForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Reasoning using Flan T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src import T5ModelForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "from utils import process_config\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/column_reasoning/flant5.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import SciGenDataset\n",
    "from utils import create_synthetic_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_synthetic_column(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SciGenDataset(dataset, config, data_type = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ModelForConditionalGeneration(config)\n",
    "model.load_state_dict(torch.load(\"logs/column_reasoning_flant5/checkpoints/epoch=5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "\n",
    "    batch = test_dataset.__getitem__(index)\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = batch\n",
    "    actual_output_ids = labels.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                            num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0))\n",
    "\n",
    "    print(\"Input sequence: \\t\\t\", tokenizer.decode(input_ids, skip_special_tokens = True), end = \"\\n\\n\")\n",
    "    print(\"Actual output: \\t\\t\", tokenizer.decode(labels, skip_special_tokens = True), end = \"\\n\\n\")\n",
    "    print(\"Predicted output: \\t\", tokenizer.decode(output_ids.squeeze(0), skip_special_tokens = True), end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAPEX with MLM Checkpoint Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from utils import process_config\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import WikiTQDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WikiTQDataset(dataset, config, data_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import BartModelForGenerativeQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_mlm_pretrained_epochs30/checkpoints/epoch=15.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from easydict import EasyDict\n",
    "from torch.utils.data import DataLoader\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        old_x = x\n",
    "\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        \n",
    "        if x == old_x:\n",
    "            break\n",
    "    \n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    \n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        \n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        \n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        \n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        \n",
    "        assert isinstance(other, Value)\n",
    "        \n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        \n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        \n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    \n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    \n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    \n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    \n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    \n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    \n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = decoder_input_ids.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\")).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_sequence = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    pred = to_value_list([predicted_sequence])\n",
    "    gold = to_value_list([actual_sequence])\n",
    "\n",
    "    verdict = check_denotation(pred, gold)\n",
    "\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_mlm_pretrained_epochs30/checkpoints/epoch=20.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = decoder_input_ids.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:1\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:1\")).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_sequence = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    pred = to_value_list([predicted_sequence])\n",
    "    gold = to_value_list([actual_sequence])\n",
    "\n",
    "    verdict = check_denotation(pred, gold)\n",
    "\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_mlm_pretrained_epochs30/checkpoints/epoch=10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = decoder_input_ids.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:3\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:3\")).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_sequence = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    print(predicted_sequence)\n",
    "    print(actual_sequence)\n",
    "\n",
    "    # return False\n",
    "\n",
    "    pred = to_value_list([predicted_sequence])\n",
    "    gold = to_value_list([actual_sequence])\n",
    "\n",
    "    verdict = check_denotation(pred, gold)\n",
    "\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_mlm_pretrained_epochs30/checkpoints/epoch=10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = decoder_input_ids.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:3\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:3\")).squeeze().detach().cpu()\n",
    "\n",
    "    predicted_sequence = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    # print(predicted_sequence)\n",
    "    # return predicted_sequence\n",
    "    # print(actual_sequence)\n",
    "\n",
    "    pred = to_value_list([predicted_sequence])\n",
    "    gold = to_value_list([actual_sequence])\n",
    "\n",
    "    verdict = check_denotation(pred, gold)\n",
    "\n",
    "    return pred, gold, verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    pred, gold, verdict = evaluate(i)\n",
    "    output_dict[i] = {\"pred\": pred, \"gold\": gold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in output_dict.items():\n",
    "    x[str(key)] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tapex_mlm_ckpt_wikitq_preds_epoch10.pkl\", \"wb\") as f:\n",
    "    pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"tapex_mlm_ckpt_wikitq_preds_epoch10.json\", \"w\") as f:\n",
    "    json.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import WikiTQDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"tapex_mlm_ckpt_wikitq_preds_epoch10.json\", \"r\") as f:\n",
    "    l = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(config.data.data_path)\n",
    "test_dataset = WikiTQDataset(dataset, config, data_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import BartModelForGenerativeQuestionAnswering\n",
    "model = BartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_mlm_pretrained_epochs30/checkpoints/epoch=10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROW COL Embeddings Code fix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<s> how many runs batted in did darren daulton have? col : name | season(s) | position(s) | notes row 1 : omar daal | 2000–2001 | pitcher |  15–16 record\\n4.52 earned run average\\n158 row 2 : babe dahlgren | 1943 | first baseman | .287 batting average\\n5 home runs\\n56 runs batted in row 3 : sam dailey | 1929 | pitcher |  2–2 record\\n7.54 earned run average\\n18 row 4 : ed daily | 1885–1887 | outfielder\\npitcher | .230 batting average\\n6 home runs\\n42–36 record row 5 : clay dalrymple | 1960–1968 | catcher | .234 batting average\\n50 home runs\\n312 runs batted in row 6 : tony daniels | 1945 | second baseman | .200 batting average\\n2 triples\\n10 runs batted in row 7 : alvin dark | 1960 | third baseman | .242 batting average\\n3 home runs\\n14 runs batted in row 8 : george darrow | 1934 | pitcher |  2–6 record\\n5.51 earned run average\\n14 row 9 : darren daulton§ | 1983\\n1985–1997 | catcher | .245 batting average\\n134 home runs\\n567 runs batted row 10 : curt davis | 1934–1936 | pitcher |  37–35 record\\n3.42 earned run average\\n191 row 11 : dick davis | 1981–1982 | right fielder | .311 batting average\\n4 home runs\\n26 runs batted in row 12 : dixie davis | 1918 | pitcher |  0–2 record\\n3.06 earned run average\\n18 row 13 : jacke davis | 1962 | left fielder | .213 batting average\\n1 home run\\n6 runs batted in row 14 : kane davis | 2007 | pitcher |  0–1 record\\n5.56 earned run average\\n10 row 15 : kiddo davis | 1932\\n1934 | center fielder | .302 batting average\\n11 triples\\n105 runs batted in row 16 : mark davis | 1980–1981\\n1993 | pitcher |  2–6 record\\n6.31 earned run average\\n62 row 17 : spud davis | 1928–1933\\n1938–1939 | catcher | .321 batting average\\n53 home runs\\n363 runs batted in row 18 : bill dawley | 1988 | pitcher |  0–2 record\\n13.50 earned run average\\n3 row 19 : bill day | 1889–1890 | pitcher |  1–4 record\\n4.10 earned run average\\n29 row 20 : justin de fratus | 2011 | pitcher |  1–0 record\\n2.25 earned run average\\n3 row 21 : valerio de los santos | 2003 | pitcher |  1–0 record\\n9.00 earned run average\\n4 row 22 : wayland dean | 1926–1927 | pitcher |  8–17 record\\n5.01 earned run average\\n53 row 23 : art decatur | 1925–1927 | pitcher |  7–18 record\\n6.18 earned run average\\n58 row 24 : harry decker | 1889–1890 | second baseman |.204 batting average\\n1 double\\n4 runs batted in row 25 : pep deininger | 1908–1909 | center fielder |.260 batting average\\n9 doubles\\n16 runs batted in row 26 : bill deitrick | 1927–1928 | left fielder\\nshortstop |.198 batting average\\n6 doubles\\n7 runs batted in row 27 : iván dejesús | 1982–1984 | shortstop | .249 batting average\\n15 triples\\n139 runs batted in row 28 : josé dejesús | 1990–1991 | pitcher |  17–17 record\\n3.55 earned run average\\n205 row 29 : bobby del greco | 1960–1961\\n1965 | center fielder | .240 batting average\\n12 home runs\\n37 runs batted in row 30 : garton del savio | 1943 | shortstop |.091 batting average\\n12 plate appearances\\n1 walk row</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"wikitablequestions\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = train_dataset[11063][\"question\"]\n",
    "table = train_dataset[11063][\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_column_names = table[\"header\"]\n",
    "table_content_values = table[\"rows\"]\n",
    "table = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(table, question, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length = 960, \n",
    "          return_tensors = \"pt\", return_token_type_ids = True, return_attention_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.decode(tokenized_input[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_config\n",
    "from src import EEDBartModelForGenerativeQuestionAnswering\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEDBartModelForGenerativeQuestionAnswering(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "layerwise_learning_rate_decay = 0.9\n",
    "weight_decay = config.training.weight_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\"]\n",
    "# initialize lr for task specific layer\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.model.lm_head.named_parameters()] + [n for n, p in model.named_parameters() if \"shared\" in n] + [n for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        # \"params\": [p for n, p in model.named_parameters() if \"shared\" in n] + [p for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "optimizer_grouped_parameters += [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.model.model.decomposer.layernorm_embedding.named_parameters()] + [n for n, p in model.model.model.encoder.layernorm_embedding.named_parameters()] + [n for n, p in model.model.model.decoder.layernorm_embedding.named_parameters()],\n",
    "        # \"params\": [p for n, p in model.named_parameters() if \"shared\" in n] + [p for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_grouped_parameters += [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.named_parameters() if \"bias\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "# decomposer_layers = [getattr(model.model.model, \"decomposer\").embed_tokens] + [getattr(model.model.model, \"decomposer\").embed_positions] \\\n",
    "#                         + list(getattr(model.model.model, \"decomposer\").layers)\n",
    "\n",
    "decomposer_layers = [getattr(model.model.model, \"decomposer\").embed_positions] + list(getattr(model.model.model, \"decomposer\").layers)\n",
    "# decomposer_layers = list(getattr(model.model.model, \"decomposer\").layers)\n",
    "# decomposer_layers = [getattr(model.model.model, \"decomposer\").embed_positions] + list(getattr(model.model.model, \"decomposer\").layers)\n",
    "\n",
    "\n",
    "# encoder_layers = [getattr(model.model.model, \"encoder\").embed_tokens] + [getattr(model.model.model, \"encoder\").embed_positions] \\\n",
    "#                         + list(getattr(model.model.model, \"encoder\").layers)\n",
    "\n",
    "encoder_layers = [getattr(model.model.model, \"encoder\").embed_positions] + list(getattr(model.model.model, \"encoder\").layers)\n",
    "# encoder_layers = list(getattr(model.model.model, \"encoder\").layers)\n",
    "\n",
    "# decoder_layers = [getattr(model.model.model, \"decoder\").embed_tokens] + [getattr(model.model.model, \"decoder\").embed_positions] \\\n",
    "                        # + list(getattr(model.model.model, \"decoder\").layers)\n",
    "\n",
    "decoder_layers = [getattr(model.model.model, \"decoder\").embed_positions] + list(getattr(model.model.model, \"decoder\").layers)\n",
    "# decoder_layers = list(getattr(model.model.model, \"decoder\").layers)\n",
    "\n",
    "# decomposer_layers = list(getattr(model.model, \"model\").decomposer)\n",
    "# encoder_layers = list(getattr(model.model, \"model\").encoder)\n",
    "# decoder_layers = list(getattr(model.model, \"model\").decoder)\n",
    "# # layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "\n",
    "\n",
    "\n",
    "# # layers.reverse()\n",
    "decomposer_layers.reverse()\n",
    "encoder_layers.reverse()\n",
    "decoder_layers.reverse()\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in decomposer_layers:\n",
    "    # if layer == \"BartLearnedPositionalEmbedding\":\n",
    "    #     print(\"\\n\\nHere\\n\\n\")\n",
    "    # print(layer)\n",
    "    print([\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "    ])\n",
    "    \n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in encoder_layers:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in decoder_layers:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in optimizer_grouped_parameters:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [getattr(model.model.model, \"encoder\").embed_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in x:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    print(layer)\n",
    "    print({\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.model.model.encoder.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([\n",
    "            {\n",
    "                \"params\": [n for n, p in model.model.model.decomposer.named_parameters() if \"bias\" in n] + [n for n, p in model.model.model.encoder.named_parameters() if \"bias\" in n] + [n for n, p in model.model.model.decoder.named_parameters() if \"bias\" in n],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": learning_rate,\n",
    "            },\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\"]\n",
    "# initialize lr for task specific layer\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.model.lm_head.named_parameters()] + [n for n, p in model.named_parameters() if \"shared\" in n] + [n for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        # \"params\": [p for n, p in model.named_parameters() if \"shared\" in n] + [p for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "optimizer_grouped_parameters += [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.model.model.decomposer.layernorm_embedding.named_parameters() if \"bias\" not in n] + [n for n, p in model.model.model.encoder.layernorm_embedding.named_parameters() if \"bias\" not in n] + [n for n, p in model.model.model.decoder.layernorm_embedding.named_parameters() if \"bias\" not in n],\n",
    "        # \"params\": [p for n, p in model.named_parameters() if \"shared\" in n] + [p for n, p in model.named_parameters() if \"token_classifier\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_grouped_parameters += [\n",
    "    {\n",
    "        \"params\": [n for n, p in model.model.model.decomposer.named_parameters() if \"bias\" in n] + [n for n, p in model.model.model.encoder.named_parameters() if \"bias\" in n] + [n for n, p in model.model.model.decoder.named_parameters() if \"bias\" in n],\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    "]\n",
    "\n",
    "# decomposer_layers = [getattr(model.model.model, \"decomposer\").embed_tokens] + [getattr(model.model.model, \"decomposer\").embed_positions] \\\n",
    "#                         + list(getattr(model.model.model, \"decomposer\").layers)\n",
    "\n",
    "decomposer_layers = [getattr(model.model.model, \"decomposer\").embed_positions] + list(getattr(model.model.model, \"decomposer\").layers)\n",
    "# decomposer_layers = list(getattr(model.model.model, \"decomposer\").layers)\n",
    "\n",
    "\n",
    "# encoder_layers = [getattr(model.model.model, \"encoder\").embed_tokens] + [getattr(model.model.model, \"encoder\").embed_positions] \\\n",
    "#                         + list(getattr(model.model.model, \"encoder\").layers)\n",
    "\n",
    "encoder_layers = [getattr(model.model.model, \"encoder\").embed_positions] + list(getattr(model.model.model, \"encoder\").layers)\n",
    "# encoder_layers = list(getattr(model.model.model, \"encoder\").layers)\n",
    "\n",
    "# decoder_layers = [getattr(model.model.model, \"decoder\").embed_tokens] + [getattr(model.model.model, \"decoder\").embed_positions] \\\n",
    "                        # + list(getattr(model.model.model, \"decoder\").layers)\n",
    "\n",
    "decoder_layers = [getattr(model.model.model, \"decoder\").embed_positions] + list(getattr(model.model.model, \"decoder\").layers)\n",
    "# decoder_layers = list(getattr(model.model.model, \"decoder\").layers)\n",
    "\n",
    "# decomposer_layers = list(getattr(model.model, \"model\").decomposer)\n",
    "# encoder_layers = list(getattr(model.model, \"model\").encoder)\n",
    "# decoder_layers = list(getattr(model.model, \"model\").decoder)\n",
    "# # layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "\n",
    "\n",
    "\n",
    "# # layers.reverse()\n",
    "decomposer_layers.reverse()\n",
    "encoder_layers.reverse()\n",
    "decoder_layers.reverse()\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in decomposer_layers:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        # {\n",
    "        #     \"params\": [p for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "        #     \"weight_decay\": 0.0,\n",
    "        #     \"lr\": lr,\n",
    "        # },\n",
    "    ]\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in encoder_layers:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        # {\n",
    "        #     \"params\": [p for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "        #     \"weight_decay\": 0.0,\n",
    "        #     \"lr\": lr,\n",
    "        # },\n",
    "    ]\n",
    "\n",
    "lr = learning_rate\n",
    "for layer in decoder_layers:\n",
    "    lr *= layerwise_learning_rate_decay\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n],\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        # {\n",
    "        #     \"params\": [p for n, p in layer.named_parameters() if \"bias\" in n],\n",
    "        #     \"weight_decay\": 0.0,\n",
    "        #     \"lr\": lr,\n",
    "        # },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in optimizer_grouped_parameters:\n",
    "    print(x, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.model.model.decomposer.embed_positions.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [getattr(model.model.model, \"encoder\").embed_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in x:\n",
    "    print({\"params\": [n for n, p in layer.named_parameters() if \"bias\" not in n]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in optimizer_grouped_parameters:\n",
    "    count += len(x[\"params\"])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposer_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

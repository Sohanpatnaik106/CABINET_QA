{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "from src import TapexModelForConditionalGeneration, TapexModelForMaskedLanguageModelling\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data import SciGenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/tapex_baseline_mlm.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.name == \"scigen\":\n",
    "    train_dataset = SciGenDataset(dataset, config, \"train\")\n",
    "    validation_dataset = SciGenDataset(dataset, config, \"validation\")\n",
    "    test_dataset = SciGenDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.training.training_type == \"masked_language_modelling\":\n",
    "    model = TapexModelForMaskedLanguageModelling.load_from_checkpoint(config.model.checkpoint)\n",
    "else:\n",
    "    model = TapexModelForConditionalGeneration.load_from_checkpoint(config.model.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index, data_type = \"test\"):\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        data = train_dataset\n",
    "    elif data_type == \"val\":\n",
    "        data = validation_dataset\n",
    "    elif data_type == \"test\":\n",
    "        data = test_dataset\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, output_ids = data.__getitem__(index)\n",
    "    actual_text = data.text_input[index]\n",
    "    actual_table = data.table[index]\n",
    "    output_text = data.text_output[index]\n",
    "\n",
    "    masked_indices = (output_ids != -100)\n",
    "\n",
    "    output_ids_actual = tokenizer(answer = output_text, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                                    padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                                    max_length = config.tokenizer.max_length, return_tensors = config.tokenizer.return_tensors)\n",
    "\n",
    "    actual_output = tokenizer.decode(output_ids_actual[\"input_ids\"][0])\n",
    "\n",
    "    output = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), output_ids.unsqueeze(0).cuda(0))\n",
    "    logits = output['logits'].detach().cpu()\n",
    "\n",
    "    predicted_ids = logits.argmax(-1)[0]\n",
    "    output_ids_actual[\"input_ids\"][0][masked_indices] = predicted_ids[masked_indices]\n",
    "\n",
    "    predicted_output = tokenizer.decode(output_ids_actual[\"input_ids\"][0])\n",
    "\n",
    "    masked_input = tokenizer.decode(input_ids)\n",
    "\n",
    "    print(f\"Actual table caption: \\t {actual_text.split('</s>')[0]}\")\n",
    "    print(f\"Actual text: \\t\\t {actual_text.split('</s>')[1]}\")\n",
    "    print(f\"Masked input (no cap): \\t {masked_input.split('</s>')[1]}\")\n",
    "    print(f\"Actual Output: \\t\\t {actual_output}\")\n",
    "    print(f\"Predicted output: \\t {predicted_output}\")\n",
    "    print(f\"Input Table:\")\n",
    "    display(actual_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(150, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(5, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(30, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(200, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(123, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, token_type_ids, output_ids = test_dataset.__getitem__(index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids, attention_mask, token_type_ids, output_ids = test_dataset.__getitem__(index)    \n",
    "actual_text = test_dataset.text_input[index]\n",
    "actual_table = test_dataset.table[index]\n",
    "\n",
    "output = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), output_ids.unsqueeze(0).cuda(0))\n",
    "logits = output['logits'].detach().cpu()\n",
    "\n",
    "predicted_ids = logits.argmax(-1)[0]\n",
    "predicted_output = tokenizer.decode(predicted_ids)\n",
    "\n",
    "masked_input = tokenizer.decode(input_ids)\n",
    "\n",
    "print(f\"Actual table caption: \\t {actual_text.split('</s>')[0]}\")\n",
    "print(f\"Actual text: \\t\\t {actual_text.split('</s>')[1]}\")\n",
    "print(f\"Masked input (no cap): \\t {masked_input.split('</s>')[1]}\")\n",
    "print(f\"Predicted output: \\t {predicted_output}\")\n",
    "print(f\"Input Table:\")\n",
    "display(actual_table)\n",
    "\n",
    "print(compute_metrics(logits.squeeze(), output_ids, tokenizer = tokenizer, config = config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "from src import TapexModelForConditionalGeneration, TapexModelForMaskedLanguageModelling\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data import SciGenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/tapex_baseline.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.name == \"scigen\":\n",
    "    train_dataset = SciGenDataset(dataset, config, \"train\")\n",
    "    validation_dataset = SciGenDataset(dataset, config, \"validation\")\n",
    "    test_dataset = SciGenDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.training.training_type == \"masked_language_modelling\":\n",
    "    model = TapexModelForMaskedLanguageModelling.load_from_checkpoint(config.model.checkpoint)\n",
    "else:\n",
    "    model = TapexModelForConditionalGeneration.load_from_checkpoint(config.model.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index, data_type = \"test\"):\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        input_ids, attention_mask, token_type_ids, output_ids = train_dataset.__getitem__(index)\n",
    "        actual_text_input = train_dataset.text_input[index]\n",
    "        actual_table = train_dataset.table[index]\n",
    "        actual_text_output = train_dataset.text_output[index]\n",
    "    elif data_type == \"val\":\n",
    "        input_ids, attention_mask, token_type_ids, output_ids = validation_dataset.__getitem__(index)     \n",
    "        actual_text_input = validation_dataset.text_input[index]\n",
    "        actual_table = validation_dataset.table[index]\n",
    "        actual_text_output = validation_dataset.text_output[index]\n",
    "    elif data_type == \"test\":\n",
    "        input_ids, attention_mask, token_type_ids, output_ids = test_dataset.__getitem__(index)    \n",
    "        actual_text_input = test_dataset.text_input[index]\n",
    "        actual_table = test_dataset.table[index]\n",
    "        actual_text_output = test_dataset.text_output[index]\n",
    "\n",
    "    output = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), output_ids.unsqueeze(0).cuda(0))\n",
    "    logits = output['logits'].detach().cpu()\n",
    "    \n",
    "    predicted_ids = logits.argmax(-1)[0]\n",
    "    predicted_output = tokenizer.decode(predicted_ids)\n",
    "\n",
    "    print(f\"Actual text input: \\t {actual_text_input}\")\n",
    "    print(f\"Actual_text_output: \\t {actual_text_output}\")\n",
    "    print(f\"Predicted output: \\t {predicted_output}\")\n",
    "    print(f\"Input Table:\")\n",
    "    display(actual_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(20, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "from src import TapexModelForConditionalGeneration, TapexModelForMaskedLanguageModelling, TapexModelForSequenceClassification\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data import SciGenDataset, TabFactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/tapex_baseline_tabfact.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path, config.data.config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.name == \"tabfact\":\n",
    "    train_dataset = TabFactDataset(dataset, config, \"train\")\n",
    "    validation_dataset = TabFactDataset(dataset, config, \"validation\")\n",
    "    test_dataset = TabFactDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TapexModelForSequenceClassification.load_from_checkpoint(\"experiment_dir/factver/factver_v1_mlm/checkpoints/epoch=2-step=8652.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index, data_type = \"test\"):\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        data = train_dataset\n",
    "    elif data_type == \"val\":\n",
    "        data = validation_dataset\n",
    "    elif data_type == \"test\":\n",
    "        data = test_dataset\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, label = data.__getitem__(index)\n",
    "    actual_text = data.text_input[index]\n",
    "    actual_table = data.table[index]\n",
    "\n",
    "    output = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), label.unsqueeze(0).cuda(0))\n",
    "    logits = output['logits'].detach().cpu()\n",
    "\n",
    "    pred = logits.argmax(-1)[0]\n",
    "\n",
    "    # print(f\"Actual text: \\t\\t {actual_text}\")\n",
    "    # print(f\"Actual Output: \\t\\t {label}\")\n",
    "    # print(f\"Predicted output: \\t {pred}\")\n",
    "    # print(f\"Input Table:\")\n",
    "    # display(actual_table)\n",
    "\n",
    "    return actual_text, label, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(110, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(50, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(87, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(200, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.text_input[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fact_len = []\n",
    "correct_fact_len = []\n",
    "for index in tqdm(range(test_dataset.__len__()), position = 0, leave = True, total = test_dataset.__len__()):\n",
    "    actual_text, label, pred = predict(index, \"test\")\n",
    "    if label != pred:\n",
    "        error_fact_len.append(len(actual_text.split(\"</s>\")[0].split()))\n",
    "    else: \n",
    "        correct_fact_len.append(len(actual_text.split(\"</s>\")[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(error_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(error_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(error_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(correct_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(correct_fact_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Reasoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed, create_synthetic_column\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from data import SciGenDataset\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import Trainer, Logger\n",
    "\n",
    "\n",
    "from src import BartModelForMaskedLM, BartModelForConditionalGeneration, BartModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/tapex_baseline_mlm.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.name == \"scigen\":\n",
    "    # train_dataset = SciGenDataset(dataset, config, \"train\")\n",
    "    # validation_dataset = SciGenDataset(dataset, config, \"validation\")\n",
    "    test_dataset = SciGenDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(config.model.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer\n",
    "model = BartModelForMaskedLM(config)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(config.model.checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index, data_type = \"test\"):\n",
    "\n",
    "    # if data_type == \"train\":\n",
    "    #     data = train_dataset\n",
    "    # elif data_type == \"val\":\n",
    "    #     data = validation_dataset\n",
    "    # elif data_type == \"test\":\n",
    "    data = test_dataset\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = data.__getitem__(index)\n",
    "    \n",
    "    actual_text = data.text_input[index]\n",
    "    actual_table = data.table[index]\n",
    "    output_text = data.text_output[index]\n",
    "\n",
    "    logits = model(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), \n",
    "                                    attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"), \n",
    "                                    decoder_input_ids = decoder_input_ids.unsqueeze(0).to(\"cuda:0\")).squeeze().detach().cpu()\n",
    "\n",
    "    # predicted_words = model.module.model.generate(inputs = input_ids.unsqueeze(0).to(\"cuda:0\"), num_beams=4, num_return_sequences=4).detach().cpu().squeeze()\n",
    "    # print(predicted_words)\n",
    "\n",
    "    print(f\"Actual text: {actual_text}\")\n",
    "    print(f\"Masked text: {tokenizer.batch_decode(input_ids.unsqueeze(0))}\")\n",
    "    print(f\"Output words: {tokenizer.batch_decode(labels[labels != -100].unsqueeze(0))}\")\n",
    "    print(f\"Predicted words: {tokenizer.batch_decode(logits.argmax(-1)[labels != -100].unsqueeze(0))}\")\n",
    "    # print(f\"Predicted words: {tokenizer.batch_decode(predicted_words, skip_special_tokens=True)}\")\n",
    "    print(f\"Table: \")\n",
    "    display(actual_table)\n",
    "    \n",
    "    # print(logits.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # # logits = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), output_ids.unsqueeze(0).cuda(0))\n",
    "\n",
    "    # masked_indices = (output_ids != -100)\n",
    "\n",
    "    # output_ids_actual = tokenizer(answer = output_text, add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "    #                                 padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "    #                                 max_length = config.tokenizer.max_length, return_tensors = config.tokenizer.return_tensors)\n",
    "\n",
    "    # actual_output = tokenizer.decode(output_ids_actual[\"input_ids\"][0])\n",
    "\n",
    "    # output = model(input_ids.unsqueeze(0).cuda(0), attention_mask.unsqueeze(0).cuda(0), token_type_ids.unsqueeze(0).cuda(0), output_ids.unsqueeze(0).cuda(0))\n",
    "    # logits = output['logits'].detach().cpu()\n",
    "\n",
    "    # predicted_ids = logits.argmax(-1)[0]\n",
    "    # output_ids_actual[\"input_ids\"][0][masked_indices] = predicted_ids[masked_indices]\n",
    "\n",
    "    # predicted_output = tokenizer.decode(output_ids_actual[\"input_ids\"][0])\n",
    "\n",
    "    # masked_input = tokenizer.decode(input_ids)\n",
    "\n",
    "    # print(f\"Actual table caption: \\t {actual_text.split('</s>')[0]}\")\n",
    "    # print(f\"Actual text: \\t\\t {actual_text.split('</s>')[1]}\")\n",
    "    # print(f\"Masked input (no cap): \\t {masked_input.split('</s>')[1]}\")\n",
    "    # print(f\"Actual Output: \\t\\t {actual_output}\")\n",
    "    # print(f\"Predicted output: \\t {predicted_output}\")\n",
    "    # print(f\"Input Table:\")\n",
    "    # display(actual_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(5, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(10, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(11, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(12, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dolly Inference (Verbalised and Non verbalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoXForCausalLM.from_pretrained(\"databricks/dolly-v2-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import json\n",
    "from utils import process_config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import set_seed\n",
    "import pickle\n",
    "\n",
    "\n",
    "from src import TapexModelForConditionalGeneration, TapexModelForMaskedLanguageModelling\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data import SciGenDataset, TabFactDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/dolly_tab_fact.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path, config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.name == \"tabfact\":\n",
    "    # train_dataset = SciGenDataset(dataset, config, \"train\")\n",
    "    # validation_dataset = SciGenDataset(dataset, config, \"validation\")\n",
    "    test_dataset = TabFactDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_table(table):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu().to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(index, verbalise = False, decompose = False):\n",
    "\n",
    "    text = test_dataset.text_input[index]\n",
    "    label = test_dataset.label[index]\n",
    "    table = test_dataset.table[index]\n",
    "\n",
    "    display(table)\n",
    "\n",
    "    if verbalise:\n",
    "        table_copy = deepcopy(table)\n",
    "        list_of_lists = table_copy.values.tolist()\n",
    "        column_names = table_copy.columns.tolist()\n",
    "        resList = [column_names]+list_of_lists\n",
    "        # print(resList)\n",
    "\n",
    "        num_rows = len(resList)\n",
    "        num_cols = len(resList[0])\n",
    "        column_names =  resList[0]\n",
    "        table = \"[HEADER] \" + \" \".join(column_names)\n",
    "        # y = tokenizer.special_tokens_map['sep_token']\n",
    "        z = tokenizer.special_tokens_map['eos_token']\n",
    "        table += \" \".join(\n",
    "        [\n",
    "            \n",
    "            f\" [ROW] {' '.join([f'Cell ({row},{col+1}) has {resList[row][col]} {z}' for col in range(num_cols)])}\" if row != (num_rows - 1)\n",
    "            \n",
    "            else f\" [ROW] {' '.join([f'Cell ({row},{col+1}) has {resList[row][col]} {z}' for col in range(num_cols)])}\" for row in range(1, num_rows)\n",
    "            \n",
    "        ]\n",
    "        ) \n",
    "\n",
    "    else:\n",
    "        table_column_names = list(table.columns)\n",
    "        table_content_values = table.values.tolist()\n",
    "        table = \"[HEADER] \" + \" \".join(table_column_names)\n",
    "        for row in table_content_values:\n",
    "            table += \" [ROW] \" + \" \".join(row) \n",
    "\n",
    "\n",
    "\n",
    "    text_input = f\"State whether the following fact is correct using the table with proper reason <s> {text} <s> {table}\"\n",
    "    print(f\"Text input: {text_input}\")\n",
    "    tokenized_input = tokenizer(text_input, return_tensors=\"pt\")\n",
    "\n",
    "    # print(tokenized_input[\"input_ids\"])\n",
    "    # return\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(tokenized_input[\"input_ids\"].to(\"cuda:1\"), num_beams = 3, max_new_tokens = 30)\n",
    "\n",
    "    print(f\"Fact: {text}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    # print(output)\n",
    "    print(tokenizer.batch_decode(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(0, verbalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(1, verbalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(0, verbalise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(7, verbalise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(7, verbalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(10, verbalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(10, verbalise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference of MPT on WikiTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src import MPTModelForGenerativeQuestionAnswering\n",
    "from utils import process_config, prepare_dataloaders\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/mpt.json\", \"r\") as f:\n",
    "    config = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, validation_dataloader, test_dataloader, tokenizer = prepare_dataloaders(dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MPTModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_mpt7b_standard/checkpoints/epoch=30.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from easydict import EasyDict\n",
    "from torch.utils.data import DataLoader\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        old_x = x\n",
    "\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        \n",
    "        if x == old_x:\n",
    "            break\n",
    "    \n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    \n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        \n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        \n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        \n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        \n",
    "        assert isinstance(other, Value)\n",
    "        \n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        \n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        \n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    \n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    \n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    \n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    \n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    \n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    \n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "        self.sum = 0\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "metrics = {\"accuracy\": AverageMeter()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataloader):\n",
    "\n",
    "    with tqdm(dataloader, unit = \"batch\", position = 0, leave = True, desc = \"Metrics\") as tepoch:\n",
    "        for batch_idx, batch in enumerate(tepoch):\n",
    "            \n",
    "\n",
    "            if config.model.use_position_ids:\n",
    "                raise NotImplementedError\n",
    "                input_ids, attention_mask, token_type_ids, decoder_input_ids, position_ids, labels = batch\n",
    "\n",
    "                # model.module.generate(input_ids = input_ids, attention_mask = attention_mask, tokenizer = tokenizer)\n",
    "                output_ids = model.model.generate(input_ids = input_ids.to(device), attention_mask = attention_mask.to(device), \n",
    "                                                        max_length = config.tokenizer.output_max_length, \n",
    "                                                        num_beams = 3, early_stopping = True, position_ids = position_ids.to(device))\n",
    "\n",
    "            else:\n",
    "                if config.model.type == \"encoder-decoder\":\n",
    "                    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = batch\n",
    "                    actual_output_ids = labels.clone()\n",
    "                    output_ids = model.model.generate(input_ids = input_ids.to(\"cuda:0\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                            num_beams = 3, early_stopping = True, attention_mask = attention_mask.to(\"cuda:0\")).detach().cpu()\n",
    "                elif config.model.type == \"decoder-only\":\n",
    "                    input_ids, attention_mask, token_type_ids, inference_input_ids, inference_attention_mask, actual_output_ids, labels = batch\n",
    "                    output_ids = model.model.generate(input_ids = inference_input_ids.to(\"cuda:0\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                                        num_beams = 3, early_stopping = True, attention_mask = inference_attention_mask.to(\"cuda:0\")).detach().cpu()\n",
    "\n",
    "            predicted_sequence = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "            if config.model.type == \"decoder-only\":\n",
    "                for i in range(len(predicted_sequence)):\n",
    "                    predicted_sequence[i] = predicted_sequence[i].replace(tokenizer.decode(inference_input_ids[i], skip_special_tokens = True), \"\")\n",
    "            \n",
    "            actual_sequence = tokenizer.batch_decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "            for a, p in zip(actual_sequence, predicted_sequence):\n",
    "                pred = to_value_list([p])\n",
    "                gold = to_value_list([a])\n",
    "\n",
    "                print(pred)\n",
    "                print(gold)\n",
    "                exit(0)\n",
    "\n",
    "                correct = check_denotation(pred, gold)\n",
    "\n",
    "                if correct:\n",
    "                    metrics[\"accuracy\"].update(1, 1)\n",
    "                else:\n",
    "                    metrics[\"accuracy\"].update(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality measurement of Bert Based decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"datasets/wiki_tq/test_soft_decomposition.pkl\", \"rb\") as f:\n",
    "    decomposed_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_soft_decomposition(index):\n",
    "\n",
    "    question = dataset[\"test\"][index][\"question\"]\n",
    "    answers = dataset[\"test\"][index][\"answers\"]\n",
    "\n",
    "    table_column_names = dataset[\"test\"][index][\"table\"][\"header\"]\n",
    "    table_content_values = dataset[\"test\"][index][\"table\"][\"rows\"]\n",
    "    table = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "    \n",
    "    table_decomposed = decomposed_table[index]\n",
    "    \n",
    "    print(\"\\n\\nQuestion: \", question)\n",
    "    print(\"\\n\\Answer: \", answers)\n",
    "\n",
    "    print(\"\\n\\nActual table: \")\n",
    "    display(table)\n",
    "    print(\"\\n\\nDecomposed table:\")\n",
    "    display(table_decomposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_soft_decomposition(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of number of tables where answer is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][\"table\"][\"rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "    answers = train_dataset[i][\"answers\"]\n",
    "    rows = train_dataset[i][\"table\"][\"rows\"]\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(test_dataset)), position = 0, leave = True, total = len(test_dataset)):\n",
    "    answers = test_dataset[i][\"answers\"]\n",
    "    rows = test_dataset[i][\"table\"][\"rows\"]\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(val_dataset)), position = 0, leave = True, total = len(val_dataset)):\n",
    "    answers = val_dataset[i][\"answers\"]\n",
    "    rows = val_dataset[i][\"table\"][\"rows\"]\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/wiki_tq/train_soft_decomposition.pkl\", \"rb\") as f:\n",
    "    train_soft_decomposition = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "    answers = train_dataset[i][\"answers\"]\n",
    "    for i in range(len(answers)):\n",
    "        answers[i] = str(answers[i]).lower()\n",
    "    \n",
    "    table = train_soft_decomposition[i]\n",
    "    rows = table.values.tolist()\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/wiki_tq/test_soft_decomposition.pkl\", \"rb\") as f:\n",
    "    test_soft_decomposition = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(test_dataset)), position = 0, leave = True, total = len(test_dataset)):\n",
    "    answers = test_dataset[i][\"answers\"]\n",
    "    for i in range(len(answers)):\n",
    "        answers[i] = str(answers[i]).lower()\n",
    "    \n",
    "    table = test_soft_decomposition[i]\n",
    "    rows = table.values.tolist()\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/wiki_tq/validation_soft_decomposition.pkl\", \"rb\") as f:\n",
    "    validation_soft_decomposition = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(validation_dataset)), position = 0, leave = True, total = len(validation_dataset)):\n",
    "    answers = validation_dataset[i][\"answers\"]\n",
    "    for i in range(len(answers)):\n",
    "        answers[i] = str(answers[i]).lower()\n",
    "    \n",
    "    table = validation_soft_decomposition[i]\n",
    "    rows = table.values.tolist()\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if flag:\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATER Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dater_outputs/saved/results/wtq/gloc_wtq_end2end_wikitq_test.json\", \"r\") as f:\n",
    "    test_preds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "u\"\"\"Official Evaluator for WikiTableQuestions Dataset\n",
    "There are 3 value types\n",
    "1. String (unicode)\n",
    "2. Number (float)\n",
    "3. Date (a struct with 3 fields: year, month, and date)\n",
    "   Some fields (but not all) can be left unspecified. However, if only the year\n",
    "   is specified, the date is automatically converted into a number.\n",
    "Target denotation = a set of items\n",
    "- Each item T is a raw unicode string from Mechanical Turk\n",
    "- If T can be converted to a number or date (via Stanford CoreNLP), the\n",
    "    converted value (number T_N or date T_D) is precomputed\n",
    "Predicted denotation = a set of items\n",
    "- Each item P is a string, a number, or a date\n",
    "- If P is read from a text file, assume the following\n",
    "  - A string that can be converted into a number (float) is converted into a\n",
    "    number\n",
    "  - A string of the form \"yyyy-mm-dd\" is converted into a date. Unspecified\n",
    "    fields can be marked as \"xx\". For example, \"xx-01-02\" represents the date\n",
    "    January 2nd of an unknown year.\n",
    "  - Otherwise, it is kept as a string\n",
    "The predicted denotation is correct if\n",
    "1. The sizes of the target denotation and the predicted denotation are equal\n",
    "2. Each item in the target denotation matches an item in the predicted\n",
    "    denotation\n",
    "A target item T matches a predicted item P if one of the following is true:\n",
    "1. normalize(raw string of T) and normalize(string form of P) are identical.\n",
    "   The normalize method performs the following normalizations on strings:\n",
    "   - Remove diacritics (é → e)\n",
    "   - Convert smart quotes (‘’´`“”) and dashes (‐‑‒–—−) into ASCII ones\n",
    "   - Remove citations (trailing •♦†‡*#+ or [...])\n",
    "   - Remove details in parenthesis (trailing (...))\n",
    "   - Remove outermost quotation marks\n",
    "   - Remove trailing period (.)\n",
    "   - Convert to lowercase\n",
    "   - Collapse multiple whitespaces and strip outermost whitespaces\n",
    "2. T can be interpreted as a number T_N, P is a number, and P = T_N\n",
    "3. T can be interpreted as a date T_D, P is a date, and P = T_D\n",
    "   (exact match on all fields; e.g., xx-01-12 and 1990-01-12 do not match)\n",
    "\"\"\"\n",
    "__version__ = '1.0.2'\n",
    "\n",
    "import sys, os, re, argparse\n",
    "import unicodedata\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "################ String Normalization ################\n",
    "\n",
    "def normalize(x):\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "    while True:\n",
    "        old_x = x\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        if x == old_x:\n",
    "            break\n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "################ Value Types ################\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "################ Value Instantiation ################\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "################ Check the Predicted Denotations ################\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "################ Batch Mode ################\n",
    "\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--tagged-dataset-path',\n",
    "                        default='../../datasets/wtq/raw_dataset/wtq/tagged/data',\n",
    "                        help='Directory containing CoreNLP-tagged dataset TSV file')\n",
    "    parser.add_argument('--validation-ids-path',\n",
    "                        default='omnitab_download/wtq/validation_ids.txt',\n",
    "                        help='File containing ids of the validation set.')\n",
    "    parser.add_argument('--split', default='validation',\n",
    "                        help='On which split to evaluate prediction_path. Could be \"test\" or \"validation\"')\n",
    "    parser.add_argument('--separator', default=', ',\n",
    "                        help='Separator used to concat multiple answer entities')\n",
    "    parser.add_argument('--prediction_path',default='gloc_wtq_end2end_wikitq_validation_all.json',\n",
    "                        help='Path to the prediction file. Each line contains one prediction')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # ID string --> list[Value]\n",
    "    target_values_map = {}\n",
    "    for filename in os.listdir(args.tagged_dataset_path):\n",
    "        if filename[0]=='.':\n",
    "            continue\n",
    "        filename = os.path.join(args.tagged_dataset_path, filename)\n",
    "        print('Reading dataset from', filename)\n",
    "        with open(filename, 'r', 'utf8') as fin:\n",
    "            header = fin.readline().rstrip('\\n').split('\\t')\n",
    "            for line in fin:\n",
    "                stuff = dict(zip(header, line.rstrip('\\n').split('\\t')))\n",
    "                ex_id = stuff['id']\n",
    "                original_strings = tsv_unescape_list(stuff['targetValue'])\n",
    "                canon_strings = tsv_unescape_list(stuff['targetCanon'])\n",
    "\n",
    "                target_values_map[ex_id] = to_value_list(\n",
    "                    original_strings, canon_strings)\n",
    "    # validation_ids = list(map(lambda x: x.strip(), open(args.validation_ids_path, 'r')))\n",
    "    # print('Read', len(target_values_map), 'examples')\n",
    "    # print(target_values_map)\n",
    "    st2id = {}\n",
    "    import json\n",
    "    import collections\n",
    "    import numpy as np\n",
    "    if args.split == 'test':\n",
    "        with open(os.path.join('../../datasets/wtq','test_lower.jsonl')) as f:\n",
    "            lines = f.readlines()\n",
    "            for l in lines:\n",
    "                dic = json.loads(l)\n",
    "                st = dic['statement']\n",
    "                ids = dic['ids']\n",
    "                st2id[st] = ids\n",
    "        with open('gloc_wtq_end2end_wikitq_test.json','r') as f:\n",
    "            dic = json.load(f)\n",
    "        print('test')\n",
    "    if args.split == 'validation':\n",
    "        with open(os.path.join('../../datasets/wtq','valid_lower.jsonl')) as f:\n",
    "            lines = f.readlines()\n",
    "            for l in lines:\n",
    "                dic = json.loads(l)\n",
    "                st = dic['statement']\n",
    "                ids = dic['ids']\n",
    "                st2id[st] = ids\n",
    "        with open('gloc_wtq_end2end_wikitq_validation.json','r') as f:\n",
    "            dic = json.load(f)\n",
    "        print('val')\n",
    "        # with open('gloc_wtq_end2end_wikitq_validation_wo_sql.json','r') as f:\n",
    "        #     dic = json.load(f)\n",
    "        \n",
    "\n",
    "        \n",
    "    num_examples, num_correct = 0, 0\n",
    "    simple_right = 0\n",
    "    simple = 0\n",
    "    cmplex_right = 0\n",
    "\n",
    "    cmplex = 0\n",
    "    large = 0\n",
    "    small = 0\n",
    "    deno_acc = 0\n",
    "    for key in dic:\n",
    "        to_union = collections.defaultdict(float)\n",
    "        it = dic[key]\n",
    "        table = it['data_item']['table_text']\n",
    "        st = it['data_item']['statement']\n",
    "        ######### col filed################\n",
    "        preds = it['generations']\n",
    "        \n",
    "        for pred in preds:\n",
    "            log_prob_mean = pred[2]\n",
    "            pred = pred[0]\n",
    "\n",
    "            pred = pred.split('therefore,the answer is :')[-1]\n",
    "            \n",
    "            key = pred\n",
    "            to_union[key] += np.exp(log_prob_mean)\n",
    "        d_ordered = sorted(to_union.items(),key=lambda x:x[1],reverse=True)\n",
    "        try:\n",
    "            pred_answer = d_ordered[0][0].split('\\n')[0].strip()\n",
    "        except Exception:\n",
    "            pred_answer = 'error'\n",
    "        st = st.split('\\n')[0]\n",
    "        target_values = target_values_map[st2id[st]]\n",
    "        # treat pred as an single entity because of 2 prompt with out example\n",
    "        # if len(target_values) == 1:\n",
    "        #     pred_answer = [pred_answer]\n",
    "        # else:\n",
    "        #     pred_answer = pred_answer.split(',')\n",
    "        \n",
    "        # treat pred answer as only on entity\n",
    "        pred_answer = [pred_answer]\n",
    "        pred_answer = to_value_list(pred_answer)\n",
    "        # print(pred_answer,target_values)\n",
    "        # if len(st.split(' '))>=10:\n",
    "        #     cmplex += 1\n",
    "        #     if check_denotation(target_values,pred_answer):\n",
    "        #         cmplex_right += 1\n",
    "        # else:\n",
    "        #     simple += 1\n",
    "        #     if check_denotation(target_values,pred_answer):\n",
    "        #         simple_right += 1\n",
    "        if check_denotation(target_values,pred_answer):\n",
    "            deno_acc += 1 \n",
    "    print('Denotation Accuracy',deno_acc/len(dic))\n",
    "    # print(len(dic))\n",
    "    # print(simple)\n",
    "    # print(cmplex)\n",
    "    # print('s',simple_right/simple)\n",
    "    # print('c',cmplex_right/cmplex)\n",
    "#     print('Reading predictions from', args.prediction_path)\n",
    "#     num_examples, num_correct = 0, 0\n",
    "#     with open(args.prediction_path, 'r', 'utf8') as fin:\n",
    "#         for lid, line in enumerate(fin):\n",
    "#             if args.split == 'test':\n",
    "#                 ex_id = f'nu-{lid}'\n",
    "#             elif args.split == 'validation':\n",
    "#                 ex_id = validation_ids[lid]\n",
    "#             else:\n",
    "#                 raise NotImplementedError\n",
    "#             line = line.rstrip('\\n').strip()\n",
    "\n",
    "#             # treat each as single-entity or multi-entity answer based on the ground truth\n",
    "#             # if len(target_values_map[ex_id]) == 1:\n",
    "#             #     predictions = [line]\n",
    "#             # else:\n",
    "#             #     predictions = line.split(args.separator)\n",
    "#             predictions = [line]\n",
    "#             if ex_id not in target_values_map:\n",
    "#                 print\n",
    "#                 'WARNING: Example ID \"%s\" not found' % ex_id\n",
    "#             else:\n",
    "#                 target_values = target_values_map[ex_id]\n",
    "#                 predicted_values = to_value_list(predictions)\n",
    "#                 correct = check_denotation(target_values, predicted_values)\n",
    "#                 print\n",
    "#                 u'%s\\t%s\\t%s\\t%s' % (ex_id, correct,\n",
    "#                                      target_values, predicted_values)\n",
    "#                 num_examples += 1\n",
    "#                 if correct:\n",
    "#                     num_correct += 1\n",
    "#     print('Examples:', num_examples)\n",
    "#     print('Correct:', num_correct)\n",
    "#     print('Accuracy:', round((num_correct + 1e-9) / (num_examples + 1e-9), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list = []\n",
    "questions_list = []\n",
    "actual_answers_list = []\n",
    "predicted_answers_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_files_instances(dic):\n",
    "    for i, key in tqdm(enumerate(dic), position = 0, leave = True):\n",
    "        to_union = collections.defaultdict(float)\n",
    "        it = dic[key]\n",
    "        table = it['data_item']['table_text']\n",
    "\n",
    "        headers = table[0]\n",
    "        rows = table[1:]\n",
    "        question = it[\"data_item\"][\"statement\"]\n",
    "        table = pd.DataFrame.from_dict({str(col).lower(): [str(rows[j][i]).lower() for j in range(len(rows))] for i, col in enumerate(headers)})\n",
    "\n",
    "        # display(table)\n",
    "\n",
    "        st = it['data_item']['statement']\n",
    "        ######### col filed################\n",
    "        preds = it['generations']\n",
    "\n",
    "        actual_answer = it[\"data_item\"][\"answer\"]\n",
    "        rows = table.values.tolist()\n",
    "        flag = False \n",
    "        for row in rows:\n",
    "            for ans in actual_answer:\n",
    "                if ans.lower() in row:\n",
    "                    flag = True\n",
    "        \n",
    "        # total += 1\n",
    "        \n",
    "        for pred in preds:\n",
    "            log_prob_mean = pred[2]\n",
    "            pred = pred[0]\n",
    "\n",
    "            pred = pred.split('therefore,the answer is :')[-1]\n",
    "            \n",
    "            key = pred\n",
    "            to_union[key] += np.exp(log_prob_mean)\n",
    "        d_ordered = sorted(to_union.items(),key=lambda x:x[1],reverse=True)\n",
    "        try:\n",
    "            pred_answer = d_ordered[0][0].split('\\n')[0].strip()\n",
    "        except Exception:\n",
    "            pred_answer = 'error'\n",
    "        st = st.split('\\n')[0]\n",
    "\n",
    "        if not flag:\n",
    "            # count += 1\n",
    "            tables_list.append(table)\n",
    "            questions_list.append(question)\n",
    "            actual_answers_list.append(actual_answer)\n",
    "            predicted_answers_list.append(pred_answer)\n",
    "\n",
    "        # print(pred_answer)\n",
    "        # print(actual_answer)\n",
    "\n",
    "        # print(table)\n",
    "        # if i == 0:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_files_instances(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(index):\n",
    "\n",
    "    table = tables_list[index]\n",
    "    question = questions_list[index]\n",
    "    actual_answer = actual_answers_list[index]\n",
    "    predicted_answer = predicted_answers_list[index]\n",
    "\n",
    "    print(\"\\n\\nQuestion: \", question)\n",
    "    print(\"\\n\\nActual Answer: \", actual_answer)\n",
    "    print(\"\\n\\nPredicted Answer: \", predicted_answer)\n",
    "    print(\"\\n\\nTable\")\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki TQ Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list = []\n",
    "questions_list = []\n",
    "answers_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_dataset)), position = 0, leave = True, total = len(train_dataset)):\n",
    "    question = train_dataset[i][\"question\"]\n",
    "    answers = train_dataset[i][\"answers\"]\n",
    "    rows = train_dataset[i][\"table\"][\"rows\"]\n",
    "    headers = train_dataset[i][\"table\"][\"header\"]\n",
    "    flag = False \n",
    "    for row in rows:\n",
    "        for ans in answers:\n",
    "            if ans in row:\n",
    "                flag = True\n",
    "\n",
    "    if not flag:\n",
    "        table = pd.DataFrame.from_dict({str(col).lower(): [str(rows[j][i]).lower() for j in range(len(rows))] for i, col in enumerate(headers)})\n",
    "\n",
    "        tables_list.append(table)\n",
    "        questions_list.append(question)\n",
    "        answers_list.append(answers)\n",
    "    # if flag:\n",
    "    #     count += 1\n",
    "    # total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tables_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(index):\n",
    "    question = questions_list[index]\n",
    "    table = tables_list[index]\n",
    "    answers = answers_list[index]\n",
    "\n",
    "    print(\"\\n\\nQuestion: \", question)\n",
    "    print(\"\\n\\nAnswers\", answers)\n",
    "    print(\"\\n\\nTable:\")\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Verbalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_numbers(strings):\n",
    "    # Define lookup tables for various place values\n",
    "    units = ['', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    tens = ['', '', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety']\n",
    "    teens = ['ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n",
    "    scales = ['', 'thousand', 'million', 'billion', 'trillion', 'quadrillion', 'quintillion']\n",
    "\n",
    "    expanded_strings = []\n",
    "    for string in strings:\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*|\\d+', string)  # Regular expression to match numbers\n",
    "        if match:\n",
    "            number = match.group()\n",
    "            number = number.replace(',', '')  # Remove commas if present\n",
    "            number = int(number)\n",
    "            if number == 0:\n",
    "                expanded_string = 'zero'\n",
    "            else:\n",
    "                num_parts = []\n",
    "                scale_count = 0\n",
    "                while number > 0:\n",
    "                    num_part = number % 1000  # Consider the last 3 digits\n",
    "                    if num_part > 0:\n",
    "                        num_part_words = []\n",
    "                        hundreds_digit = num_part // 100\n",
    "                        if hundreds_digit > 0:\n",
    "                            num_part_words.append(units[hundreds_digit])\n",
    "                            num_part_words.append('hundred')\n",
    "                        tens_digit = (num_part // 10) % 10\n",
    "                        units_digit = num_part % 10\n",
    "                        if tens_digit == 1:\n",
    "                            num_part_words.append(teens[units_digit])\n",
    "                        else:\n",
    "                            if tens_digit > 1:\n",
    "                                num_part_words.append(tens[tens_digit])\n",
    "                            if units_digit > 0:\n",
    "                                num_part_words.append(units[units_digit])\n",
    "                        num_parts.append(' '.join(num_part_words) + ' ' + scales[scale_count])\n",
    "                    number //= 1000\n",
    "                    scale_count += 1\n",
    "                num_parts.reverse()\n",
    "                expanded_string = ' '.join(num_parts)\n",
    "            expanded_string = string.replace(match.group(), expanded_string)  # Replace number in string\n",
    "            expanded_strings.append(expanded_string)\n",
    "        else:\n",
    "            expanded_strings.append(string)\n",
    "    return expanded_strings\n",
    "\n",
    "# Example usage\n",
    "strings = ['The number is 145216.', 'Another example: 100,000.', 'No number in this string.']\n",
    "expanded_strings = expand_numbers(strings)\n",
    "for string in expanded_strings:\n",
    "    print(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_numbers(strings):\n",
    "    # Define lookup tables for various place values\n",
    "    units = ['', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    tens = ['', '', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety']\n",
    "    teens = ['ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n",
    "    scales = ['', 'thousand', 'lakh', 'crore']\n",
    "\n",
    "    expanded_strings = []\n",
    "    for string in strings:\n",
    "        match = re.search(r'\\d{1,10}(?:,\\d{3})*|\\d+', string)  # Regular expression to match numbers\n",
    "        print(match)\n",
    "        if match:\n",
    "            number = match.group()\n",
    "            number = number.replace(',', '')  # Remove commas if present\n",
    "            number = int(number)\n",
    "            if number == 0:\n",
    "                expanded_string = 'zero'\n",
    "            else:\n",
    "                num_parts = []\n",
    "                scale_count = 0\n",
    "                while number > 0:\n",
    "                    num_part = number % 1000  # Consider the last 3 digits\n",
    "                    if num_part > 0:\n",
    "                        num_part_words = []\n",
    "                        hundreds_digit = num_part // 100\n",
    "                        if hundreds_digit > 0:\n",
    "                            num_part_words.append(units[hundreds_digit])\n",
    "                            num_part_words.append('hundred')\n",
    "                        tens_digit = (num_part // 10) % 10\n",
    "                        units_digit = num_part % 10\n",
    "                        if tens_digit == 1:\n",
    "                            num_part_words.append(teens[units_digit])\n",
    "                        else:\n",
    "                            if tens_digit > 1:\n",
    "                                num_part_words.append(tens[tens_digit])\n",
    "                            if units_digit > 0:\n",
    "                                num_part_words.append(units[units_digit])\n",
    "                        num_parts.append(' '.join(num_part_words) + ' ' + scales[scale_count])\n",
    "                    number //= 1000\n",
    "                    scale_count += 1\n",
    "                num_parts.reverse()\n",
    "                expanded_string = ' '.join(num_parts)\n",
    "            expanded_string = string.replace(match.group(), expanded_string)  # Replace number in string\n",
    "            expanded_strings.append(expanded_string)\n",
    "        else:\n",
    "            expanded_strings.append(string)\n",
    "    return expanded_strings\n",
    "\n",
    "# Example usage\n",
    "strings = ['The number is 10207.', 'Another example: 100,000.', 'No number in this string.']\n",
    "expanded_strings = expand_numbers(strings)\n",
    "for string in expanded_strings:\n",
    "    print(string)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable decomposition analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import EEDBartModelForGenerativeQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from utils import process_config\n",
    "from data import WikiTQDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)\n",
    "test_dataset = WikiTQDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEDBartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_eed_soft_decomposition_epochs30/checkpoints/epoch=15.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = labels.clone()\n",
    "    \n",
    "\n",
    "    token_scores = model.model.model.sigmoid(model.model.model.token_classifier(model.model.model.decomposer(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"))[0]))\n",
    "\n",
    "    print(tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    input_ids = input_ids.detach().cpu()[token_scores.squeeze().detach().cpu() > 0.93]\n",
    "    print(tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True))\n",
    "    # print(token_scores)\n",
    "    # output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "    #                                                         num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"))\n",
    "\n",
    "    # predicted_sequence = tokenizer.decode(output_ids.squeeze(), skip_special_tokens=True)\n",
    "    # actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    # print(predicted_sequence)\n",
    "    # print(actual_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question + Irrelevant table - anwers analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import BartModelForGenerativeQuestionAnswering\n",
    "from data import WikiTQDataset\n",
    "from utils import process_config\n",
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WikiTQDataset(dataset, config, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartModelForGenerativeQuestionAnswering(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        old_x = x\n",
    "\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        \n",
    "        if x == old_x:\n",
    "            break\n",
    "    \n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    \n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        \n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        \n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        \n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        \n",
    "        assert isinstance(other, Value)\n",
    "        \n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        \n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        \n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    \n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    \n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    \n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    \n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    \n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    \n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = train_dataset.__getitem__(index)\n",
    "\n",
    "    actual_output_ids = labels.clone()\n",
    "    output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(device), max_new_tokens = config.tokenizer.output_max_length, \n",
    "                                            num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(device))\n",
    "\n",
    "    \n",
    "    p = tokenizer.decode(output_ids.squeeze(0), skip_special_tokens=True)\n",
    "    a = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "    pred = to_value_list([p])\n",
    "    gold = to_value_list([a])\n",
    "    verdict = check_denotation(pred, gold)\n",
    "\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with whole table as input (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(train_dataset.__len__()), position = 0, leave = True, total = train_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with decomposed table as input (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(train_dataset.__len__()), position = 0, leave = True, total = train_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with irrelevant decomposed table as input (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(train_dataset.__len__()), position = 0, leave = True, total = train_dataset.__len__()):\n",
    "    verdict = evaluate(i)\n",
    "    if verdict:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Decomposition regularisation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import EEDBartModelForGenerativeQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from utils import process_config\n",
    "from data import WikiTQDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq/tapex.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config.data.data_path)\n",
    "test_dataset = WikiTQDataset(dataset, config, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEDBartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"logs/table_question_answering_tapex_eed_with_kldiv_flattened_reg_low_weight/checkpoints/epoch=30.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = test_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = test_dataset.__getitem__(index)\n",
    "    actual_output_ids = labels.clone()\n",
    "    \n",
    "\n",
    "    token_scores = model.model.model.sigmoid(model.model.model.token_classifier(model.model.model.decomposer(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"))[0]))\n",
    "    # token_scores = model.model.model.token_classifier(model.model.model.decomposer(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"))[0])\n",
    "    # print(token_scores)\n",
    "\n",
    "    print(tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    input_ids = input_ids.detach().cpu()[token_scores.squeeze().detach().cpu() >= torch.mean(token_scores.detach().cpu())]\n",
    "    print(tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True))\n",
    "    # output_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), max_new_tokens = config.tokenizer.output_max_length, \n",
    "    #                                                         num_beams = 3, early_stopping = True, attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"))\n",
    "\n",
    "    # predicted_sequence = tokenizer.decode(output_ids.squeeze(), skip_special_tokens=True)\n",
    "    # actual_sequence = tokenizer.decode(actual_output_ids, skip_special_tokens = True)\n",
    "\n",
    "    # print(predicted_sequence)\n",
    "    # print(actual_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

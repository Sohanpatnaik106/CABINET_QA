{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from src import CluBartModelForGenerativeQuestionAnswering\n",
    "from utils import process_config\n",
    "from datasets import load_dataset\n",
    "\n",
    "from data import WikiTQWithReasonAsInputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_tq_bootstrap/tapex.json\", \"rb\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CluBartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"/dev/shm/tabllm/logs/table_question_answering_omnitab_cluster_with_flant5_reason_as_input_train_splitted/checkpoints/epoch=10.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WikiTQWithReasonAsInputDataset(dataset = dataset, config = config, data_type = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from codecs import open\n",
    "from math import isnan, isinf\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = x.decode('utf8', errors='ignore')\n",
    "\n",
    "    # Remove diacritics\n",
    "    x = ''.join(c for c in unicodedata.normalize('NFKD', x)\n",
    "                if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Normalize quotes and dashes\n",
    "    x = re.sub(r\"[‘’´`]\", \"'\", x)\n",
    "    x = re.sub(r\"[“”]\", \"\\\"\", x)\n",
    "    x = re.sub(r\"[‐‑‒–—−]\", \"-\", x)\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        old_x = x\n",
    "\n",
    "        # Remove citations\n",
    "        x = re.sub(r\"((?<!^)\\[[^\\]]*\\]|\\[\\d+\\]|[•♦†‡*#+])*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove details in parenthesis\n",
    "        x = re.sub(r\"(?<!^)( \\([^)]*\\))*$\", \"\", x.strip())\n",
    "        \n",
    "        # Remove outermost quotation mark\n",
    "        x = re.sub(r'^\"([^\"]*)\"$', r'\\1', x.strip())\n",
    "        \n",
    "        if x == old_x:\n",
    "            break\n",
    "    \n",
    "    # Remove final '.'\n",
    "    if x and x[-1] == '.':\n",
    "        x = x[:-1]\n",
    "    \n",
    "    # Collapse whitespaces and convert to lower case\n",
    "    x = re.sub(r'\\s+', ' ', x, flags=re.U).lower().strip()\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class Value(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Should be populated with the normalized string\n",
    "    _normalized = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def match(self, other):\n",
    "        \"\"\"Return True if the value matches the other value.\n",
    "\n",
    "        Args:\n",
    "            other (Value)\n",
    "        Returns:\n",
    "            a boolean\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def normalized(self):\n",
    "        return self._normalized\n",
    "\n",
    "\n",
    "class StringValue(Value):\n",
    "\n",
    "    def __init__(self, content):\n",
    "        assert isinstance(content, str)\n",
    "        self._normalized = normalize(content)\n",
    "        self._hash = hash(self._normalized)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, StringValue) and self.normalized == other.normalized\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'S' + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        return self.normalized == other.normalized\n",
    "\n",
    "\n",
    "class NumberValue(Value):\n",
    "\n",
    "    def __init__(self, amount, original_string=None):\n",
    "        assert isinstance(amount, (int, float))\n",
    "        if abs(amount - round(amount)) < 1e-6:\n",
    "            self._amount = int(amount)\n",
    "        else:\n",
    "            self._amount = float(amount)\n",
    "        if not original_string:\n",
    "            self._normalized = str(self._amount)\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        self._hash = hash(self._amount)\n",
    "\n",
    "    @property\n",
    "    def amount(self):\n",
    "        return self._amount\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NumberValue) and self.amount == other.amount\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('N(%f)' % self.amount) + str([self.normalized])\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        assert isinstance(other, Value)\n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        if isinstance(other, NumberValue):\n",
    "            return abs(self.amount - other.amount) < 1e-6\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a number.\n",
    "\n",
    "        Return:\n",
    "            the number (int or float) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return int(text)\n",
    "        except:\n",
    "            try:\n",
    "                amount = float(text)\n",
    "                assert not isnan(amount) and not isinf(amount)\n",
    "                return amount\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "class DateValue(Value):\n",
    "\n",
    "    def __init__(self, year, month, day, original_string=None):\n",
    "\n",
    "        \"\"\"Create a new DateValue. Placeholders are marked as -1.\"\"\"\n",
    "        assert isinstance(year, int)\n",
    "        assert isinstance(month, int) and (month == -1 or 1 <= month <= 12)\n",
    "        assert isinstance(day, int) and (day == -1 or 1 <= day <= 31)\n",
    "        assert not (year == month == day == -1)\n",
    "        \n",
    "        self._year = year\n",
    "        self._month = month\n",
    "        self._day = day\n",
    "        \n",
    "        if not original_string:\n",
    "            self._normalized = '{}-{}-{}'.format(\n",
    "                year if year != -1 else 'xx',\n",
    "                month if month != -1 else 'xx',\n",
    "                day if day != '-1' else 'xx')\n",
    "        else:\n",
    "            self._normalized = normalize(original_string)\n",
    "        \n",
    "        self._hash = hash((self._year, self._month, self._day))\n",
    "\n",
    "    @property\n",
    "    def ymd(self):\n",
    "        return (self._year, self._month, self._day)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DateValue) and self.ymd == other.ymd\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._hash\n",
    "\n",
    "    def __str__(self):\n",
    "        return (('D(%d,%d,%d)' % (self._year, self._month, self._day))\n",
    "                + str([self._normalized]))\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    def match(self, other):\n",
    "        \n",
    "        assert isinstance(other, Value)\n",
    "        \n",
    "        if self.normalized == other.normalized:\n",
    "            return True\n",
    "        \n",
    "        if isinstance(other, DateValue):\n",
    "            return self.ymd == other.ymd\n",
    "        \n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(text):\n",
    "        \"\"\"Try to parse into a date.\n",
    "\n",
    "        Return:\n",
    "            tuple (year, month, date) if successful; otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ymd = text.lower().split('-')\n",
    "            assert len(ymd) == 3\n",
    "            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n",
    "            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n",
    "            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n",
    "            assert not (year == month == day == -1)\n",
    "            assert month == -1 or 1 <= month <= 12\n",
    "            assert day == -1 or 1 <= day <= 31\n",
    "            return (year, month, day)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def to_value(original_string, corenlp_value=None):\n",
    "    \"\"\"Convert the string to Value object.\n",
    "\n",
    "    Args:\n",
    "        original_string (basestring): Original string\n",
    "        corenlp_value (basestring): Optional value returned from CoreNLP\n",
    "    Returns:\n",
    "        Value\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(original_string, Value):\n",
    "        # Already a Value\n",
    "        return original_string\n",
    "    \n",
    "    if not corenlp_value:\n",
    "        corenlp_value = original_string\n",
    "    \n",
    "    # Number?\n",
    "    amount = NumberValue.parse(corenlp_value)\n",
    "    \n",
    "    if amount is not None:\n",
    "        return NumberValue(amount, original_string)\n",
    "    \n",
    "    # Date?\n",
    "    ymd = DateValue.parse(corenlp_value)\n",
    "    if ymd is not None:\n",
    "        if ymd[1] == ymd[2] == -1:\n",
    "            return NumberValue(ymd[0], original_string)\n",
    "        else:\n",
    "            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n",
    "    \n",
    "    # String.\n",
    "    return StringValue(original_string)\n",
    "\n",
    "\n",
    "def to_value_list(original_strings, corenlp_values=None):\n",
    "    \"\"\"Convert a list of strings to a list of Values\n",
    "\n",
    "    Args:\n",
    "        original_strings (list[basestring])\n",
    "        corenlp_values (list[basestring or None])\n",
    "    Returns:\n",
    "        list[Value]\n",
    "    \"\"\"\n",
    "    assert isinstance(original_strings, (list, tuple, set))\n",
    "    if corenlp_values is not None:\n",
    "        assert isinstance(corenlp_values, (list, tuple, set))\n",
    "        assert len(original_strings) == len(corenlp_values)\n",
    "        return list(set(to_value(x, y) for (x, y)\n",
    "                        in zip(original_strings, corenlp_values)))\n",
    "    else:\n",
    "        return list(set(to_value(x) for x in original_strings))\n",
    "\n",
    "\n",
    "def check_denotation(target_values, predicted_values):\n",
    "    \"\"\"Return True if the predicted denotation is correct.\n",
    "\n",
    "    Args:\n",
    "        target_values (list[Value])\n",
    "        predicted_values (list[Value])\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "\n",
    "    # Check size\n",
    "    if len(target_values) != len(predicted_values):\n",
    "        return False\n",
    "    \n",
    "    # Check items\n",
    "    for target in target_values:\n",
    "        if not any(target.match(pred) for pred in predicted_values):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def tsv_unescape(x):\n",
    "    \"\"\"Unescape strings in the TSV file.\n",
    "    Escaped characters include:\n",
    "        newline (0x10) -> backslash + n\n",
    "        vertical bar (0x7C) -> backslash + p\n",
    "        backslash (0x5C) -> backslash + backslash\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a unicode\n",
    "    \"\"\"\n",
    "    return x.replace(r'\\n', '\\n').replace(r'\\p', '|').replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "\n",
    "def tsv_unescape_list(x):\n",
    "    \"\"\"Unescape a list in the TSV file.\n",
    "    List items are joined with vertical bars (0x5C)\n",
    "\n",
    "    Args:\n",
    "        x (str or unicode)\n",
    "    Returns:\n",
    "        a list of unicodes\n",
    "    \"\"\"\n",
    "    return [tsv_unescape(y) for y in x.split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = train_dataset.__getitem__(index)\n",
    "\n",
    "    predicted_ids = model.model.generate(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"),\n",
    "                                         max_new_tokens = 64, num_beams = 3, early_stopping=True).squeeze().cpu()\n",
    "\n",
    "    predicted_sequence = tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
    "    actual_sequence = tokenizer.decode(labels[labels != -100], skip_special_tokens=True)\n",
    "\n",
    "    gold = [x.strip() for x in actual_sequence.split(\",\")]\n",
    "    pred = [x.strip() for x in predicted_sequence.split(\",\")]\n",
    "\n",
    "    pred = to_value_list(pred)\n",
    "    gold = to_value_list(gold)\n",
    "\n",
    "    verdict = check_denotation(gold, pred)\n",
    "\n",
    "    return predicted_sequence, actual_sequence, verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer_list = []\n",
    "actual_answer_list = []\n",
    "verdict_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/bootstrap1_val_indices.pkl\", \"rb\") as f:\n",
    "    indices_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(indices_list)), position = 0, leave = True, total = len(indices_list)):\n",
    "\n",
    "    idx = indices_list[i]\n",
    "    predicted_sequence, actual_sequence, verdict = evaluate(idx)\n",
    "    predicted_answer_list.append(predicted_sequence)\n",
    "    actual_answer_list.append(actual_sequence)\n",
    "    verdict_list.append(verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(len(verdict_list) - np.sum(verdict_list)) / np.sum(verdict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(index, i):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, labels = train_dataset.__getitem__(index)\n",
    "\n",
    "\n",
    "    predicted_answer_labels = tokenizer(answer = predicted_answer_list[i], add_special_tokens = config.tokenizer.add_special_tokens,\n",
    "                            padding = config.tokenizer.padding, truncation = config.tokenizer.truncation, \n",
    "                            max_length = 64, return_tensors = config.tokenizer.return_tensors,\n",
    "                            return_token_type_ids = config.tokenizer.return_token_type_ids,\n",
    "                            return_attention_mask = config.tokenizer.return_attention_mask)[\"input_ids\"]\n",
    "\n",
    "    predicted_target_labels = predicted_answer_labels.clone().squeeze()\n",
    "    predicted_target_labels[:-1] = predicted_target_labels[1:].clone()\n",
    "\n",
    "    logits = model.model(input_ids = input_ids.unsqueeze(0).to(\"cuda:0\"), attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\"),\n",
    "                         decoder_input_ids = predicted_answer_labels.to(\"cuda:0\")).logits.detach().cpu().squeeze()\n",
    "    \n",
    "\n",
    "\n",
    "    loss = F.cross_entropy(logits, predicted_target_labels, ignore_index=1)\n",
    "    perplexity = torch.exp(loss)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "    token_probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    log_probs = torch.log2(token_probs)\n",
    "    sum_log_probs = torch.sum(log_probs)\n",
    "\n",
    "    perplexity = 2 ** (-sum_log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in tqdm(enumerate(indices_list), position = 0, leave = True, total = len(indices_list)):\n",
    "    perplexity = calculate_perplexity(idx, i)\n",
    "    perplexity_list.append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = np.array(perplexity_list)\n",
    "indices = np.array(indices_list)\n",
    "\n",
    "verdicts = np.array(verdict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdicts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities[verdicts == True].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities[verdicts == True].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities[verdicts == True][perplexities[verdicts == True] < perplexities[verdicts == True].mean()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities[verdicts == True][perplexities[verdicts == True] < 1.0013].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[verdicts == True][perplexities[verdicts == True] < 1.0013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reasons[10406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/WikiTQReasoningData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/WikiTQReasoningDataBootstrap1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 850\n",
    "question = df[\"question\"][idx]\n",
    "answers = df[\"answers\"][idx]\n",
    "table = df[\"table\"][idx]\n",
    "reason = df[\"reason\"][idx]\n",
    "\n",
    "print(\"Question: \", question, end = \"\\n\\n\")\n",
    "print(\"Answers: \", answers, end = \"\\n\\n\")\n",
    "print(\"Reason: \", reason, end = \"\\n\\n\")\n",
    "print(\"Table: \", table, end = \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = indices[verdicts == True][perplexities[verdicts == True] < 1.0013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {\"id\": [],\n",
    "            \"question\": [],\n",
    "            \"table\": [],\n",
    "            \"answers\": [],\n",
    "            \"cluster_label\": [],\n",
    "            \"reason\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(filtered_indices, position = 0, leave = True, total = len(filtered_indices)):\n",
    "\n",
    "    if idx not in df.id.tolist():\n",
    "        question = dataset[\"train\"][int(idx)][\"question\"]\n",
    "        table = dataset[\"train\"][int(idx)][\"table\"]\n",
    "        answers = dataset[\"train\"][int(idx)][\"answers\"]\n",
    "        cluster_label = -1\n",
    "        reason = train_dataset.reasons[int(idx)]\n",
    "\n",
    "        new_dict[\"id\"].append(idx)\n",
    "        new_dict[\"question\"].append(question)\n",
    "        new_dict[\"table\"].append(table)\n",
    "        new_dict[\"answers\"].append(answers)\n",
    "        new_dict[\"cluster_label\"].append(cluster_label)\n",
    "        new_dict[\"reason\"].append(reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"level_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([df, new_df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/filtered_bootstrap1_train_indices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(filtered_indices.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(\"datasets/WikiTQReasoningDataBootstrap1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

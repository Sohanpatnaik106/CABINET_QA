{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import HighlightedCluBartModelForGenerativeQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "from data import WikiTQHighlightedCellsDataset\n",
    "import json\n",
    "from utils import process_config\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/wiki_sql_clustering_and_highlighting/tapex.json\", \"rb\") as f:\n",
    "    config = json.load(f)\n",
    "config = process_config(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WikiTQHighlightedCellsDataset(dataset=dataset, config=config, data_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = HighlightedCluBartModelForGenerativeQuestionAnswering(config)\n",
    "model.load_state_dict(torch.load(\"omnitab_best_ckpt/epoch=28.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_analysis(index):\n",
    "\n",
    "    input_ids, attention_mask, token_type_ids, decoder_input_ids, highlighted_cells, labels = train_dataset.__getitem__(index)\n",
    "    input_ids = input_ids.unsqueeze(0).to(\"cuda:0\")\n",
    "    attention_mask = attention_mask.unsqueeze(0).to(\"cuda:0\")\n",
    "    decoder_input_ids = decoder_input_ids.unsqueeze(0).to(\"cuda:0\")\n",
    "    highlighted_cells = highlighted_cells.unsqueeze(0).to(\"cuda:0\")\n",
    "    labels = labels.unsqueeze(0).to(\"cuda:0\")\n",
    "\n",
    "    inputs_embeds = model.model.model.decomposer.embed_tokens(input_ids) * model.model.model.decomposer.embed_scale\n",
    "\n",
    "    decomposer_outputs = model.model.model.decomposer(input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "        )\n",
    "\n",
    "    # token_scores = model.model.sigmoid(model.model.token_classifier(decomposer_outputs[0]))\n",
    "\n",
    "    latent_rep = model.model.model.latent_rep_head(decomposer_outputs[0])\n",
    "    # cluster_labels = torch.norm(latent_rep.unsqueeze(2) - model.model.model.cluster_centers.unsqueeze(0).unsqueeze(0), dim = -1).squeeze().argmin(dim = -1)\n",
    "\n",
    "    soft_labels_numerator = (1 + torch.norm((latent_rep.unsqueeze(2) - model.model.model.cluster_centers.unsqueeze(0).unsqueeze(0)), dim = -1) / model.model.model.clu_alpha) ** (-(1 + model.model.model.clu_alpha) / 2)\n",
    "    soft_labels = soft_labels_numerator / torch.sum(soft_labels_numerator, dim = -1).unsqueeze(-1)\n",
    "\n",
    "    token_scores_1 = model.model.model.token_classifier_score1(latent_rep)\n",
    "    token_scores_2 = model.model.model.token_classifier_score2(latent_rep)\n",
    "    gaussian_rvs = model.model.gaussian_dist.sample(token_scores_1.shape).to(token_scores_1.device)\n",
    "    relevance_logit = gaussian_rvs * token_scores_1 + token_scores_2\n",
    "    relevance_score = model.model.model.sigmoid(relevance_logit)\n",
    "\n",
    "    # NOTE: Uncomment as per requirement of the experiment\n",
    "    \n",
    "    # relevance_score = (0.7 * relevance_score + 0.3 * highlighted_cells.unsqueeze(-1)).squeeze()\n",
    "\n",
    "\n",
    "    # cluster_labels = torch.zeros(960)\n",
    "    # cluster_labels[relevance_score >= relevance_score.mean() - 0.018] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # x = (latent_rep - model.model.model.cluster_centers) ** 2\n",
    "    # print(x.shape)\n",
    "    # return\n",
    "\n",
    "    latent_rep = latent_rep.squeeze().detach().cpu().numpy()\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "    # Fit and transform your data\n",
    "    tsne_result = tsne.fit_transform(latent_rep)\n",
    "\n",
    "    # Fit and transform your mean vectors\n",
    "    # mean_vector1_tsne = tsne.transform([model.model.model.cluster_centers[0]])\n",
    "    # mean_vector2_tsne = tsne.transform([model.model.model.cluster_centers[1]])\n",
    "    # print(cluster_labels)\n",
    "    # return\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    # print(tsne_result.shape)\n",
    "    cluster_labels = kmeans.fit(tsne_result).labels_\n",
    "    # print(cluster_labels)\n",
    "    \n",
    "    plt.scatter(tsne_result[:, 0][cluster_labels == 0], tsne_result[:, 1][cluster_labels == 0], label='Non-relevant tokens', alpha=0.3, c = \"b\", s = 15)\n",
    "    plt.scatter(tsne_result[:, 0][cluster_labels == 1], tsne_result[:, 1][cluster_labels == 1], label='Relevant tokens', alpha=0.3, c = \"r\", s = 15)\n",
    "    # plt.scatter(tsne_result[:, 0], tsne_result[:, 1], label='Data', alpha=0.3, c = cluster_labels)\n",
    "\n",
    "    # Scatter plot for mean vectors\n",
    "    # plt.scatter(mean_vector1_tsne[0, 0], mean_vector1_tsne[0, 1], c='red', marker='x', label='Mean Vector 1')\n",
    "    # plt.scatter(mean_vector2_tsne[0, 0], mean_vector2_tsne[0, 1], c='blue', marker='x', label='Mean Vector 2')\n",
    "\n",
    "    # Add labels, legend, and title\n",
    "    # plt.xlabel('t-SNE Dimension 1')\n",
    "    # plt.ylabel('t-SNE Dimension 2')\n",
    "    \n",
    "    # plt.title('t-SNE Visualization')\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.savefig(\"clustering_fig.png\")\n",
    "\n",
    "    # print(relevance_score)\n",
    "    # print(relevance_score.mean())\n",
    "    # print(relevance_score.min())\n",
    "    # print(relevance_score.max())\n",
    "\n",
    "    print(train_dataset.tokenizer.decode(input_ids[0], skip_special_tokens = True))\n",
    "    print(\"Unsup: \", train_dataset.tokenizer.decode(input_ids[0][relevance_score.squeeze() >= relevance_score.squeeze().mean()], skip_special_tokens = True))\n",
    "    # print(\"Unsup: \", train_dataset.tokenizer.decode(input_ids[0][relevance_score.squeeze() >= 0.9], skip_special_tokens=True))\n",
    "    print(\"Highlighted cells: \", train_dataset.tokenizer.decode(input_ids[0][highlighted_cells.squeeze() == 1]))\n",
    "    print(train_dataset.tokenizer.decode(labels[labels != -100]))\n",
    "\n",
    "    table_column_names = dataset[\"train\"][index][\"table\"][\"header\"]\n",
    "    table_content_values = dataset[\"train\"][index][\"table\"][\"rows\"]\n",
    "\n",
    "    table = pd.DataFrame.from_dict({str(col).lower(): [str(table_content_values[j][i]).lower() for j in range(len(table_content_values))] for i, col in enumerate(table_column_names)})\n",
    "\n",
    "    display(table)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(1009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(3057)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset[\"train\"])):\n",
    "    if dataset[\"test\"][i][\"question\"].lower().strip() == \"in how many games did the winning team score more than 4 points?\":\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_analysis(1009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "designlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
